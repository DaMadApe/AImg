{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "from Tablero import Tablero\n",
    "from Timbiriche import Timbiriche\n",
    "def rot90(board):\n",
    "    rot = np.copy(board)\n",
    "    n = board.shape[0]\n",
    "    for i in range(n):\n",
    "        rot[:,-i-1] = board[i]\n",
    "\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            pos = rot[y,x]\n",
    "            if pos == 1:\n",
    "                rot[y,x] = 2\n",
    "            elif pos == 2:\n",
    "                rot[y,x] = 1\n",
    "            if pos in [2,3]:\n",
    "                rot[y,x] -= 1\n",
    "                rot[y-1,x] += 1\n",
    "    return rot\n",
    "\n",
    "\n",
    "tab1 = Tablero(5)\n",
    "tab1.mover(1,1,2)\n",
    "tab1.mover(1,2,1)\n",
    "tab1.mover(3,2,2)\n",
    "tab1.mover(4,2,2)\n",
    "tab2 = Tablero(5)\n",
    "tab2.tablero = rot90(tab1.tablero)\n",
    "print(tab1), print(tab2)\n",
    "np.array_str(tab1.tablero)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "4. . ._. . \n",
      "3. . ._. . \n",
      "2. . . . . \n",
      "1. ._| . . \n",
      "0. . . . . \n",
      " 0 1 2 3 4 \n",
      "\n",
      "4. . . . . \n",
      "3. . . . . \n",
      "2. . . ._. \n",
      "1| | . . . \n",
      "0. . . | . \n",
      " 0 1 2 3 4 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[[0 0 0 0 0]\\n [0 2 1 0 0]\\n [0 0 0 0 0]\\n [0 0 2 0 0]\\n [0 0 2 0 0]]'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "a,b = [1,2]\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tab1 = Tablero(4)\n",
    "tab1.mover(1,1,2)\n",
    "tab1.mover(1,2,1)\n",
    "tab1.mover(1,2,2)\n",
    "tab1.mover(0,0,2)\n",
    "tab1.mover(0,0,1)\n",
    "tab1.mover(3,2,2)\n",
    "tab1.mover(2,3,1)\n",
    "\n",
    "def rot(tab):\n",
    "    # Rotación +90 según mano derecha\n",
    "    n = tab.n\n",
    "    tab2 = Tablero(n)\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            prev = tab[y,x]\n",
    "            if prev == 1:\n",
    "                tab2[x,n-y-2] += 2\n",
    "            if prev == 2:\n",
    "                tab2[x,n-y-1] += 1\n",
    "            if prev == 3:\n",
    "                tab2[x,n-y-2] += 2\n",
    "                tab2[x,n-y-1] += 1\n",
    "    return tab2\n",
    "\n",
    "tab2 = rot(tab1)\n",
    "print(tab1), print(tab2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "3. . ._. \n",
      "2. . . | \n",
      "1. ._|_. \n",
      "0|_. . . \n",
      " 0 1 2 3 \n",
      "\n",
      "3._. . . \n",
      "2| ._| . \n",
      "1. . | . \n",
      "0. . ._| \n",
      " 0 1 2 3 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "acts = []\n",
    "n = 5\n",
    "for y in range(n):\n",
    "    for x in range(n):\n",
    "        acts.append((y,x,1))\n",
    "        acts.append((y,x,2))\n",
    "actsrot = []\n",
    "for y in range(n):\n",
    "    for x in range(n):\n",
    "        actsrot.append((x,n-y-2,2))\n",
    "        actsrot.append((x,n-y-1,1))\n",
    "actmat = np.reshape(acts, (n, n, 2, 3))\n",
    "rotmat = np.reshape(actsrot, (n, n, 2, 3))\n",
    "def rotpol(pol):\n",
    "    #   Rotación correspondiente del vector p\n",
    "    polmat = np.reshape(pol, (n, n, 2))\n",
    "    newmat = np.zeros((n, n, 2))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            newmat[n-j-1, i, 1] = polmat[i, j, 0]\n",
    "            newmat[n-j-2, i, 0] = polmat[i, j, 1]\n",
    "    return np.uint8(newmat.flatten())\n",
    "\n",
    "\n",
    "pol = range(n*n*2)\n",
    "#acts.index(tuple(rotmat[0,0,0,:]))\n",
    "#rotmat[::-1,0,0,:]\n",
    "rotmat[0,:,:,:]\n",
    "\n",
    "# rotacts = []\n",
    "# for i in range(n):\n",
    "#     for j in range(n):\n",
    "#         for m in range(2):\n",
    "#             rotacts.append(tuple(rotmat(i,j,m,:)))\n",
    "\n",
    "rotp = rotpol(list(range(2*n**2)))\n",
    "\n",
    "\n",
    "tab1 = Tablero(n)\n",
    "tab2 = Tablero(n)\n",
    "# for i in[1, 4, 6, 7]:\n",
    "#     tab1.mover(*acts[i])\n",
    "#     tab2.mover(*actsrot[i])\n",
    "# Obj: F: pol_acts [0,0,1] -> pol_rot [0, 3, 2]\n",
    "actmat[:, -1, ::-1, :]\n",
    "\n",
    "for i in [3, 5, 6, 7, 8, 9, 12, 15, 17, 45]:\n",
    "    tab1.mover(*acts[i])\n",
    "    tab2.mover(*acts[rotp[i]])\n",
    "print(tab1), print(tab2)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "4. . ._. . \n",
      "3. . . . . \n",
      "2. . . . . \n",
      "1. | ._._. \n",
      "0. ._._|_| \n",
      " 0 1 2 3 4 \n",
      "\n",
      "4. . . ._. \n",
      "3. . . |_| \n",
      "2| . . | | \n",
      "1. . ._. | \n",
      "0. . . . . \n",
      " 0 1 2 3 4 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "n = 5\n",
    "\n",
    "def rot90(tab, n):\n",
    "    # Rotación de tablero +90 según mano derecha\n",
    "    rot_tab = Tablero(n)\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            prev = tab[y,x]\n",
    "            if prev == 1:\n",
    "                rot_tab[x,n-y-2] += 2\n",
    "            if prev == 2:\n",
    "                rot_tab[x,n-y-1] += 1\n",
    "            if prev == 3:\n",
    "                rot_tab[x,n-y-2] += 2\n",
    "                rot_tab[x,n-y-1] += 1\n",
    "    return rot_tab.tablero\n",
    "\n",
    "def rot_pol90(pol, n):\n",
    "    # Rotación correspondiente del vector pi\n",
    "    polmat = np.reshape(pol, (n, n, 2))\n",
    "    newmat = np.zeros((n, n, 2))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            newmat[n-j-1, i, 1] = polmat[i, j, 0]\n",
    "            newmat[n-j-2, i, 0] = polmat[i, j, 1]\n",
    "    return newmat.flatten()\n",
    "\n",
    "def reflect(tab, n):\n",
    "    # Reflejar respecto eje x\n",
    "    ref_tab = Tablero(n)\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            prev = tab[y,x]\n",
    "            if prev == 1:\n",
    "                ref_tab[n-y-2, x] += 1\n",
    "            if prev == 2:\n",
    "                ref_tab[n-y-1, x] += 2\n",
    "            if prev == 3:\n",
    "                ref_tab[n-y-2, x] += 1\n",
    "                ref_tab[n-y-1, x] += 2\n",
    "    return ref_tab.tablero\n",
    "\n",
    "def reflect_pol(pol, n):\n",
    "    # Reflexión correspondiente de vector pi\n",
    "    polmat = np.reshape(pol, (n, n, 2))\n",
    "    newmat = np.zeros((n, n, 2))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            newmat[n-i-2, j, 0] = polmat[i, j, 0]\n",
    "            newmat[n-i-1, j, 1] = polmat[i, j, 1]\n",
    "    return newmat.flatten()\n",
    "\n",
    "pol = list(range(2*n**2))\n",
    "refp = np.uint8(rot_pol90(pol, n))\n",
    "\n",
    "tab1 = Tablero(n)\n",
    "# tab1.mover(1,1,2)\n",
    "# tab1.mover(1,2,1)\n",
    "# tab1.mover(1,2,2)\n",
    "# tab1.mover(0,0,2)\n",
    "tab2 = Tablero(n)\n",
    "# tab2.tablero = reflect(tab1, n)\n",
    "\n",
    "for i in [1, 2, 3, 4, 45]:\n",
    "    tab1.mover(*acts[i])\n",
    "    tab2.mover(*acts[refp[i]])\n",
    "\n",
    "print(tab1), print(tab2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "4. . ._. . \n",
      "3. . . . . \n",
      "2. . . . . \n",
      "1. . . . . \n",
      "0._|_| . . \n",
      " 0 1 2 3 4 \n",
      "\n",
      "4. . . . . \n",
      "3. . . . . \n",
      "2| . . ._. \n",
      "1. . . ._| \n",
      "0. . . . | \n",
      " 0 1 2 3 4 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "rotmat[0, :, :, :]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0, 3, 2],\n",
       "        [0, 4, 1]],\n",
       "\n",
       "       [[1, 3, 2],\n",
       "        [1, 4, 1]],\n",
       "\n",
       "       [[2, 3, 2],\n",
       "        [2, 4, 1]],\n",
       "\n",
       "       [[3, 3, 2],\n",
       "        [3, 4, 1]],\n",
       "\n",
       "       [[4, 3, 2],\n",
       "        [4, 4, 1]]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "c = 64\n",
    "n = 5\n",
    "convnet = nn.Sequential(\n",
    "    nn.Conv2d(1, c, 3, padding='SAME'),\n",
    "    nn.BatchNorm2d(c),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(c, c, 3, padding='SAME'),\n",
    "    nn.BatchNorm2d(c),\n",
    "    nn.ReLU()) # Salida: ()\n",
    "\n",
    "p_head = nn.Sequential(\n",
    "    nn.Conv2d(c, 2, 1),\n",
    "    nn.BatchNorm2d(2),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(2*n**2, 2*n**2),\n",
    "    nn.Softmax()) # Activación final con salida [0,1] y suma=1\n",
    "\n",
    "v_head = nn.Sequential(\n",
    "    nn.Conv2d(c, 1, 1),\n",
    "    nn.BatchNorm2d(1), #BN1D después de flatten?\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(n**2 , 1),\n",
    "    nn.Tanh())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    convnet,\n",
    "    p_head\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in model.parameters())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40508"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from Timbiriche import Tablero, Timbiriche\n",
    "tab1 = Tablero(5)\n",
    "tab1.mover(1,1,2)\n",
    "tab1.mover(1,2,1)\n",
    "tab1.mover(3,2,2)\n",
    "tab1.mover(4,2,2)\n",
    "\n",
    "g = Timbiriche(5)\n",
    "g.getValidMoves(tab1.tablero, 1)[20], g.actions[20]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, (2, 0, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = {}\n",
    "s = '1236'\n",
    "b = torch.FloatTensor([0.4124, 0.6363, 0.345262])\n",
    "a[s] = b\n",
    "a[s] = a[s] * np.array([False, True, False], dtype=np.uint8)\n",
    "torch.sum(a[s])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.6363)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "input.shape, input.unsqueeze_(dim=1).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 1, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "data = []\n",
    "for i in range(64):\n",
    "    a = torch.rand((2,2))\n",
    "    b = torch.rand(4)\n",
    "    c = torch.rand(1).item()\n",
    "    data.append((a,b,c))\n",
    "\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(tensor([[0.5301, 0.4175],\n",
       "          [0.3744, 0.7752]]),\n",
       "  tensor([0.9239, 0.7559, 0.8992, 0.7146]),\n",
       "  0.1183972954750061),\n",
       " (tensor([[0.2052, 0.7585],\n",
       "          [0.0491, 0.6261]]),\n",
       "  tensor([0.8648, 0.9329, 0.6224, 0.0378]),\n",
       "  0.2734188437461853),\n",
       " (tensor([[0.0334, 0.0909],\n",
       "          [0.1767, 0.6305]]),\n",
       "  tensor([0.4363, 0.0839, 0.5233, 0.3826]),\n",
       "  0.10066443681716919),\n",
       " (tensor([[0.3298, 0.9911],\n",
       "          [0.3823, 0.0271]]),\n",
       "  tensor([0.7836, 0.6291, 0.9605, 0.1046]),\n",
       "  0.3371305465698242),\n",
       " (tensor([[0.7134, 0.7390],\n",
       "          [0.3319, 0.6254]]),\n",
       "  tensor([0.7151, 0.4093, 0.7993, 0.2998]),\n",
       "  0.1093062162399292),\n",
       " (tensor([[0.4422, 0.6856],\n",
       "          [0.7549, 0.4617]]),\n",
       "  tensor([0.2027, 0.2416, 0.9755, 0.7430]),\n",
       "  0.03489649295806885),\n",
       " (tensor([[0.5099, 0.1195],\n",
       "          [0.1102, 0.1475]]),\n",
       "  tensor([0.0889, 0.9893, 0.7129, 0.2870]),\n",
       "  0.2894860506057739),\n",
       " (tensor([[0.6561, 0.3748],\n",
       "          [0.2570, 0.9061]]),\n",
       "  tensor([0.2959, 0.6426, 0.1787, 0.2207]),\n",
       "  0.8695873618125916),\n",
       " (tensor([[0.3393, 0.6288],\n",
       "          [0.7690, 0.7092]]),\n",
       "  tensor([0.0676, 0.7182, 0.0403, 0.0447]),\n",
       "  0.7994500994682312),\n",
       " (tensor([[0.4461, 0.0042],\n",
       "          [0.2841, 0.4988]]),\n",
       "  tensor([0.8900, 0.4731, 0.0994, 0.4975]),\n",
       "  0.09762787818908691),\n",
       " (tensor([[0.1029, 0.0390],\n",
       "          [0.2528, 0.9411]]),\n",
       "  tensor([0.7244, 0.3485, 0.1774, 0.9447]),\n",
       "  0.25820261240005493),\n",
       " (tensor([[0.7857, 0.9414],\n",
       "          [0.2386, 0.5227]]),\n",
       "  tensor([0.3367, 0.0330, 0.0483, 0.7004]),\n",
       "  0.7114241123199463),\n",
       " (tensor([[0.1668, 0.0727],\n",
       "          [0.4611, 0.7146]]),\n",
       "  tensor([0.9453, 0.6696, 0.5968, 0.7538]),\n",
       "  0.42524129152297974),\n",
       " (tensor([[0.5224, 0.7448],\n",
       "          [0.8229, 0.8829]]),\n",
       "  tensor([0.2495, 0.7833, 0.8952, 0.0036]),\n",
       "  0.7712453603744507),\n",
       " (tensor([[0.6421, 0.4464],\n",
       "          [0.4233, 0.7302]]),\n",
       "  tensor([0.8049, 0.0209, 0.0088, 0.6754]),\n",
       "  0.5085388422012329),\n",
       " (tensor([[0.0844, 0.3619],\n",
       "          [0.1695, 0.9589]]),\n",
       "  tensor([0.7776, 0.5370, 0.6692, 0.7403]),\n",
       "  0.4928947687149048),\n",
       " (tensor([[0.3955, 0.2948],\n",
       "          [0.4449, 0.9429]]),\n",
       "  tensor([0.2345, 0.0841, 0.4689, 0.4455]),\n",
       "  0.47562456130981445),\n",
       " (tensor([[0.6800, 0.3919],\n",
       "          [0.4033, 0.1144]]),\n",
       "  tensor([0.7142, 0.5532, 0.3182, 0.4028]),\n",
       "  0.7729020118713379),\n",
       " (tensor([[0.3302, 0.5659],\n",
       "          [0.6872, 0.6527]]),\n",
       "  tensor([0.3638, 0.2801, 0.3301, 0.8178]),\n",
       "  0.18837302923202515),\n",
       " (tensor([[0.2909, 0.2043],\n",
       "          [0.6753, 0.3458]]),\n",
       "  tensor([0.0548, 0.2974, 0.4303, 0.7188]),\n",
       "  0.2341705560684204),\n",
       " (tensor([[0.9801, 0.2296],\n",
       "          [0.6048, 0.0561]]),\n",
       "  tensor([0.7742, 0.0349, 0.6482, 0.9761]),\n",
       "  0.23891735076904297),\n",
       " (tensor([[0.9124, 0.7930],\n",
       "          [0.9485, 0.6144]]),\n",
       "  tensor([0.5952, 0.1418, 0.9235, 0.2446]),\n",
       "  0.9840395450592041),\n",
       " (tensor([[0.8173, 0.3739],\n",
       "          [0.0734, 0.0028]]),\n",
       "  tensor([0.3460, 0.4497, 0.2624, 0.1222]),\n",
       "  0.573459804058075),\n",
       " (tensor([[0.8282, 0.9153],\n",
       "          [0.5384, 0.9875]]),\n",
       "  tensor([0.4153, 0.8838, 0.1403, 0.7051]),\n",
       "  0.81284499168396),\n",
       " (tensor([[0.8019, 0.5535],\n",
       "          [0.4227, 0.8240]]),\n",
       "  tensor([0.7244, 0.4596, 0.7604, 0.1229]),\n",
       "  0.7216262221336365),\n",
       " (tensor([[0.5582, 0.7603],\n",
       "          [0.1666, 0.8300]]),\n",
       "  tensor([0.7139, 0.8027, 0.3259, 0.5850]),\n",
       "  0.5084896683692932),\n",
       " (tensor([[0.9289, 0.6604],\n",
       "          [0.7161, 0.2648]]),\n",
       "  tensor([0.4445, 0.6229, 0.6641, 0.0208]),\n",
       "  0.18466311693191528),\n",
       " (tensor([[0.8755, 0.6953],\n",
       "          [0.1632, 0.1674]]),\n",
       "  tensor([0.9943, 0.1298, 0.2522, 0.0409]),\n",
       "  0.13889789581298828),\n",
       " (tensor([[0.6088, 0.2010],\n",
       "          [0.7550, 0.0661]]),\n",
       "  tensor([0.7596, 0.8560, 0.2968, 0.7211]),\n",
       "  0.7527444362640381),\n",
       " (tensor([[0.3539, 0.9058],\n",
       "          [0.8865, 0.8489]]),\n",
       "  tensor([0.2469, 0.6752, 0.4427, 0.6295]),\n",
       "  0.8110340237617493),\n",
       " (tensor([[0.2649, 0.4940],\n",
       "          [0.3722, 0.4685]]),\n",
       "  tensor([0.1970, 0.7187, 0.0261, 0.2685]),\n",
       "  0.6579433083534241),\n",
       " (tensor([[0.3603, 0.7837],\n",
       "          [0.8203, 0.0505]]),\n",
       "  tensor([0.2763, 0.4796, 0.1761, 0.7658]),\n",
       "  0.6802055835723877),\n",
       " (tensor([[0.0040, 0.1592],\n",
       "          [0.3103, 0.5342]]),\n",
       "  tensor([0.5295, 0.3167, 0.3878, 0.5153]),\n",
       "  0.6938060522079468),\n",
       " (tensor([[0.3359, 0.2158],\n",
       "          [0.0576, 0.7897]]),\n",
       "  tensor([0.4987, 0.8831, 0.9628, 0.3576]),\n",
       "  0.15591806173324585),\n",
       " (tensor([[0.7306, 0.9086],\n",
       "          [0.5109, 0.1536]]),\n",
       "  tensor([0.7218, 0.9379, 0.2081, 0.7389]),\n",
       "  0.1371368169784546),\n",
       " (tensor([[0.7615, 0.9832],\n",
       "          [0.0433, 0.8456]]),\n",
       "  tensor([0.9086, 0.1556, 0.8677, 0.5048]),\n",
       "  0.7892481684684753),\n",
       " (tensor([[0.4358, 0.7441],\n",
       "          [0.8986, 0.3219]]),\n",
       "  tensor([0.7756, 0.8183, 0.4119, 0.4948]),\n",
       "  0.38773399591445923),\n",
       " (tensor([[0.8000, 0.7962],\n",
       "          [0.0762, 0.7961]]),\n",
       "  tensor([0.6318, 0.7853, 0.0220, 0.9943]),\n",
       "  0.13852691650390625),\n",
       " (tensor([[0.8027, 0.9962],\n",
       "          [0.9216, 0.4201]]),\n",
       "  tensor([0.7059, 0.8592, 0.5820, 0.7798]),\n",
       "  0.22897493839263916),\n",
       " (tensor([[0.2768, 0.4711],\n",
       "          [0.4699, 0.1460]]),\n",
       "  tensor([0.4900, 0.7233, 0.5776, 0.4428]),\n",
       "  0.7373968958854675),\n",
       " (tensor([[0.4083, 0.9611],\n",
       "          [0.7478, 0.3752]]),\n",
       "  tensor([0.0093, 0.9431, 0.1944, 0.5264]),\n",
       "  0.9843677878379822),\n",
       " (tensor([[0.6469, 0.7264],\n",
       "          [0.7101, 0.2787]]),\n",
       "  tensor([0.7061, 0.9244, 0.7501, 0.4730]),\n",
       "  0.5802984833717346),\n",
       " (tensor([[0.2205, 0.4944],\n",
       "          [0.9605, 0.1753]]),\n",
       "  tensor([0.1599, 0.3002, 0.0133, 0.4944]),\n",
       "  0.9062492847442627),\n",
       " (tensor([[0.4844, 0.6044],\n",
       "          [0.4127, 0.3496]]),\n",
       "  tensor([0.0270, 0.3685, 0.3431, 0.9384]),\n",
       "  0.6870719194412231),\n",
       " (tensor([[0.1711, 0.1390],\n",
       "          [0.5739, 0.8638]]),\n",
       "  tensor([0.1880, 0.5019, 0.9856, 0.6920]),\n",
       "  0.14422082901000977),\n",
       " (tensor([[0.6251, 0.2452],\n",
       "          [0.2903, 0.6924]]),\n",
       "  tensor([0.6091, 0.0853, 0.1482, 0.5907]),\n",
       "  0.12812989950180054),\n",
       " (tensor([[0.8604, 0.8416],\n",
       "          [0.5600, 0.2724]]),\n",
       "  tensor([0.8854, 0.1882, 0.2141, 0.0451]),\n",
       "  0.22828203439712524),\n",
       " (tensor([[0.6011, 0.0732],\n",
       "          [0.7438, 0.6680]]),\n",
       "  tensor([0.2644, 0.7267, 0.6806, 0.5923]),\n",
       "  0.9449672698974609),\n",
       " (tensor([[0.1313, 0.4350],\n",
       "          [0.0938, 0.8764]]),\n",
       "  tensor([0.1364, 0.8086, 0.6377, 0.1211]),\n",
       "  0.970492959022522),\n",
       " (tensor([[0.5659, 0.9276],\n",
       "          [0.8173, 0.1945]]),\n",
       "  tensor([0.3058, 0.3073, 0.9284, 0.5466]),\n",
       "  0.939519464969635),\n",
       " (tensor([[0.0988, 0.5893],\n",
       "          [0.5547, 0.2035]]),\n",
       "  tensor([0.8745, 0.6536, 0.8901, 0.9410]),\n",
       "  0.6679325699806213),\n",
       " (tensor([[0.8928, 0.3902],\n",
       "          [0.0586, 0.1584]]),\n",
       "  tensor([0.4724, 0.9286, 0.9307, 0.2618]),\n",
       "  0.568971574306488),\n",
       " (tensor([[0.0595, 0.8969],\n",
       "          [0.3269, 0.7186]]),\n",
       "  tensor([0.0192, 0.0797, 0.8307, 0.5002]),\n",
       "  0.6684173345565796),\n",
       " (tensor([[0.7458, 0.8195],\n",
       "          [0.7223, 0.1291]]),\n",
       "  tensor([0.6369, 0.4807, 0.3771, 0.8317]),\n",
       "  0.1644001007080078),\n",
       " (tensor([[0.1376, 0.7575],\n",
       "          [0.5683, 0.3626]]),\n",
       "  tensor([0.6743, 0.3565, 0.9719, 0.6210]),\n",
       "  0.5297644138336182),\n",
       " (tensor([[0.2007, 0.9623],\n",
       "          [0.1234, 0.7930]]),\n",
       "  tensor([0.5897, 0.8903, 0.1179, 0.1647]),\n",
       "  0.6971044540405273),\n",
       " (tensor([[0.7964, 0.3332],\n",
       "          [0.3806, 0.3589]]),\n",
       "  tensor([0.0750, 0.2465, 0.7485, 0.9321]),\n",
       "  0.784635603427887),\n",
       " (tensor([[0.6015, 0.6039],\n",
       "          [0.4275, 0.1736]]),\n",
       "  tensor([0.0136, 0.7736, 0.9807, 0.6395]),\n",
       "  0.9446190595626831),\n",
       " (tensor([[0.9544, 0.4717],\n",
       "          [0.6513, 0.5523]]),\n",
       "  tensor([0.2497, 0.7718, 0.1157, 0.6473]),\n",
       "  0.028568625450134277),\n",
       " (tensor([[0.5788, 0.8704],\n",
       "          [0.1229, 0.4115]]),\n",
       "  tensor([0.5723, 0.0292, 0.5340, 0.7165]),\n",
       "  0.370988130569458),\n",
       " (tensor([[0.8142, 0.7528],\n",
       "          [0.0352, 0.9569]]),\n",
       "  tensor([0.6709, 0.2961, 0.1327, 0.2945]),\n",
       "  0.7703893780708313),\n",
       " (tensor([[0.9229, 0.2664],\n",
       "          [0.8156, 0.5491]]),\n",
       "  tensor([0.1005, 0.0661, 0.8194, 0.2418]),\n",
       "  0.4125460982322693),\n",
       " (tensor([[0.0050, 0.3181],\n",
       "          [0.3137, 0.2353]]),\n",
       "  tensor([0.2158, 0.6440, 0.6879, 0.8765]),\n",
       "  0.11177915334701538),\n",
       " (tensor([[0.5561, 0.0373],\n",
       "          [0.2468, 0.2058]]),\n",
       "  tensor([0.2826, 0.2835, 0.9177, 0.2629]),\n",
       "  0.02269113063812256)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#torch.manual_seed(42)\n",
    "a = torch.rand((4,6))\n",
    "b = torch.argmax(a, dim=1)#.unsqueeze(dim=1)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "c = torch.randint(0, 5, (4,))\n",
    "a, b, c, loss(a, b), loss(a, c)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.7216, 0.6107, 0.5989, 0.1208, 0.0331, 0.5088],\n",
       "         [0.9559, 0.7885, 0.2089, 0.4351, 0.1314, 0.2588],\n",
       "         [0.5905, 0.7723, 0.9142, 0.0409, 0.8343, 0.1474],\n",
       "         [0.6872, 0.9231, 0.5070, 0.9549, 0.0740, 0.3090]]),\n",
       " tensor([0, 0, 2, 3]),\n",
       " tensor([4, 1, 2, 0]),\n",
       " tensor(1.4562),\n",
       " tensor(1.7371))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2cdf16027de25d041799f21881077de18674375207b67c87b0131ea69dcfb186"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}